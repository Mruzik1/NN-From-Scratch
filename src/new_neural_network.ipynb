{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def forward(self, inp: ndarray) -> ndarray:\n",
    "        return inp\n",
    "\n",
    "    def backward(self, inp: ndarray, grad_outp: ndarray):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU(Layer):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def forward(self, inp: ndarray) -> ndarray:\n",
    "        return np.where(inp>0, inp, 0)\n",
    "\n",
    "    def backward(self, inp: ndarray, grad_outp: ndarray):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid(Layer):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def forward(self, inp: ndarray):\n",
    "        return 1/(1+np.exp(-inp))\n",
    "\n",
    "    def backward(self, inp: ndarray, grad_outp: ndarray):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense(Layer):\n",
    "    def __init__(self, inp_units: int, outp_units: int, learning_rate: float = 0.1):\n",
    "        self.w = np.random.normal(size=(inp_units, outp_units))\n",
    "        self.b = np.zeros(outp_units)\n",
    "        self.lr = learning_rate\n",
    "\n",
    "    def forward(self, inp: ndarray) -> ndarray:\n",
    "        print(inp)\n",
    "        return np.dot(inp, self.w) + self.b\n",
    "\n",
    "    def backward(self, inp: ndarray, grad_outp: ndarray):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP:\n",
    "    def __init__(self):\n",
    "        self.layers = []\n",
    "\n",
    "    # adds a dense layer with the input and output shapes\n",
    "    def _add_dense(self, out_shape: int, inp_shape: int):\n",
    "        if inp_shape:\n",
    "            self.layers.append(Dense(inp_shape, out_shape))\n",
    "        elif self.layers:\n",
    "            self.layers.append(Dense(len(self.layers[-2].b), out_shape))\n",
    "        else:\n",
    "            raise AttributeError('No input shape!')\n",
    "\n",
    "    # adds an activation layer\n",
    "    def _add_activation(self, activation: str):\n",
    "        if activation.lower() == 'sigmoid':\n",
    "            self.layers.append(Sigmoid())\n",
    "        elif activation.lower() == 'relu':\n",
    "            self.layers.append(ReLU())\n",
    "        else:\n",
    "            raise AttributeError('No activation!')\n",
    "\n",
    "    # combination of two methods above\n",
    "    def add_layer(self, out_shape: int, inp_shape: int|None = None, activation: str = 'sigmoid'):\n",
    "        self._add_dense(out_shape, inp_shape)\n",
    "        self._add_activation(activation)\n",
    "\n",
    "    # cross entropy error\n",
    "    def ce_loss(self, y_hat: ndarray, y: ndarray) -> float:\n",
    "        return -np.sum(y*np.log(y_hat+1e-20))\n",
    "\n",
    "    # performs forward pass\n",
    "    def forward(self, X: ndarray) -> ndarray:\n",
    "        for layer in self.layers:\n",
    "            X = layer.forward(X)\n",
    "        return X\n",
    "\n",
    "    # predicts classes\n",
    "    def predict(self, X: ndarray) -> ndarray:\n",
    "        return np.argmax(self.forward(X), axis=0)\n",
    "\n",
    "    # training method\n",
    "    def fit(self, X: ndarray, y: ndarray):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[300 400 500]\n",
      " [  2   0   1]]\n",
      "[[792.65446484   0.         342.9262797  408.65676328   0.\n",
      "    0.        ]\n",
      " [  1.71986041   0.           2.76692293   2.16050773   0.\n",
      "    0.        ]]\n",
      "[0 1 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mykhailo\\AppData\\Local\\Temp\\ipykernel_7620\\373195030.py:6: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1+np.exp(-inp))\n"
     ]
    }
   ],
   "source": [
    "test = [[300, 400, 500], [2, 0, 1]]\n",
    "test = np.array(test)\n",
    "\n",
    "network = MLP()\n",
    "\n",
    "network.add_layer(6, inp_shape=3, activation='relu')\n",
    "network.add_layer(3)\n",
    "\n",
    "print(network.predict(test[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e96b7987e83db2bb51693718935e9a4c90615288c60e4ac5255cd193dc13706d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
